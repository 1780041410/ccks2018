{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import preprocessing\n",
    "import pickle\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unitils import get_ans,ans_clean,pre_clean,f1\n",
    "from one_jump import one_jump_solver\n",
    "from two_jump import two_jump_solver,down_to_low\n",
    "from config import df,stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unitils import from_entry,match_type_cur,get_entry,from_value,jaccard,hint,local_les,get_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYNONYM_MAP = {\n",
    "    '丈夫': '丈夫配偶',\n",
    "    '老公': '丈夫配偶',\n",
    "    '妻子': '妻子配偶',\n",
    "    '夫人': '夫人妻子配偶',\n",
    "    '媳妇': '妻子配偶',\n",
    "    '老家': '老家籍贯',\n",
    "    '故乡': '故乡籍贯',\n",
    "    '家乡': '家乡籍贯', \n",
    "    '英文':'外文英文',\n",
    "    '西班牙语':'外文西班牙语',\n",
    "    '贡献' : '贡献主要成就',\n",
    "    '功绩' : '功绩主要成就',\n",
    "    '丰功伟绩' : '丰功伟绩主要成就',\n",
    "    '来源' : '来源出处',\n",
    "    '在金庸小说《天龙八部》中':''\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_LENGTH = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_disk(var):\n",
    "    import pickle\n",
    "    import inspect\n",
    "    callers_local_vars = inspect.currentframe().f_back.f_locals.items()\n",
    "    var_name = [var_name for var_name, var_val in callers_local_vars if var_val is var][0]\n",
    "    \n",
    "    time_id = time.strftime(\"_%m_%d_%H_%M\", time.localtime())\n",
    "    \n",
    "    with open(var_name + time_id + \".bin\",\"wb\") as f:\n",
    "        pickle.dump(var,f)\n",
    "    print(var_name + time_id + \".bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取预解空间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"final_test_cache_07_19_17_35.bin\",\"rb\") as f:\n",
    "    final_test_cache = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 问题求解器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 单跳问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_MLP = load_model(\"final_one_MLP.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"one_jump_clf_07_20_12_41.bin\",\"rb\") as f:\n",
    "    one_jump_clf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_jump_feature(one_jump_feature_ans,one_jump_feature_ss,one_jump_feature_label = []):\n",
    "    \n",
    "    \"\"\"\n",
    "    raw  value 定义为 (roots,edge,ans_node)\n",
    "    \"\"\"\n",
    "    \n",
    "    anses = []\n",
    "    tmp_x = []\n",
    "    one_jump_raw = {}\n",
    "    \n",
    "    fff,raw = one_jump_solver(one_jump_feature_ans,one_jump_feature_ss)\n",
    "    \n",
    "    for key in fff:\n",
    "        anses.append(key)\n",
    "        tmp_x.append(fff[key])\n",
    "\n",
    "    try:\n",
    "        tmp_x = preprocessing.scale(tmp_x)\n",
    "\n",
    "        one_log_y = one_jump_clf.predict_proba(tmp_x)[:,1]\n",
    "        one_mlp_y = one_MLP.predict(tmp_x).reshape(-1)\n",
    "        one_mlp_y = one_mlp_y/one_mlp_y.max()\n",
    "\n",
    "        #test_one_y = 0.8*test_one_log_y + 0.2*test_one_mlp_y\n",
    "        y = 0.85*one_log_y + 0.15*one_mlp_y\n",
    "        #y = ((np.array(tmp_x) + 0.0001)*[1,1,1,1]).sum(axis = 1)\n",
    "        \n",
    "        one_jump_score = y.max()\n",
    "        one_jump_pre = [x for x,z in zip(anses,y) if z == one_jump_score]\n",
    "        \n",
    "        for high in one_jump_pre:\n",
    "            one_jump_raw[high] = raw[high]\n",
    "        \n",
    "        one_jump_vec = fff[one_jump_pre[0]]\n",
    "\n",
    "        #one_jump_pre = pre_clean(one_jump_pre)\n",
    "        \n",
    "        if one_jump_feature_label:\n",
    "            one_jump_f1 = f1(pre_clean(one_jump_pre),pre_clean(one_jump_feature_label))\n",
    "        else:\n",
    "            one_jump_f1 = 0\n",
    "\n",
    "        \n",
    "\n",
    "    except ValueError:\n",
    "        one_jump_pre = []\n",
    "        one_jump_f1 = 0\n",
    "        one_jump_vec = np.zeros(7)\n",
    "        one_jump_score = 0\n",
    "    \n",
    "    return one_jump_pre,one_jump_raw,one_jump_f1,one_jump_vec,one_jump_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 双跳问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tow_jump_model__07_11_13_23.model\n",
    "with open(\"two_jump_clf_07_14_14_57.bin\",\"rb\") as f:\n",
    "    two_jump_clf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_jump_feature(two_jump_feature_ans,two_jump_feature_ss,two_jump_feature_label = []):\n",
    "    \n",
    "    \"\"\"\n",
    "    raw value 定义为 (roots,first_edge,brige_node,second_edge,ans_node) \n",
    "    \"\"\"\n",
    "    \n",
    "    anses = []\n",
    "    tmp_x = []\n",
    "    two_jump_raw = {}\n",
    "\n",
    "    fff,raw = two_jump_solver(two_jump_feature_ans,two_jump_feature_ss)\n",
    "    aaa = down_to_low(fff)\n",
    "    for key in aaa:\n",
    "        anses.append(key)\n",
    "        tmp_x.append(fff[key])\n",
    "\n",
    "    try:\n",
    "        tmp_x = preprocessing.scale(tmp_x)\n",
    "\n",
    "        y = two_jump_clf.predict_proba(tmp_x)\n",
    "        \n",
    "        two_jump_score = y[:,1].max()\n",
    "        \n",
    "        two_jump_pre = [x for x,z in zip(anses,y[:,1]) if z == two_jump_score]\n",
    "        for high in two_jump_pre:\n",
    "            two_jump_raw[high] = raw[high]\n",
    "        \n",
    "        two_jump_vec = fff[two_jump_pre[0]]\n",
    "\n",
    "        #two_jump_pre = pre_clean(two_jump_pre)\n",
    "        \n",
    "        if two_jump_feature_label:\n",
    "            two_jump_f1 = f1(pre_clean(two_jump_pre),pre_clean(two_jump_feature_label))\n",
    "        else:\n",
    "            two_jump_f1 = 0\n",
    "\n",
    "        \n",
    "\n",
    "    except ValueError:\n",
    "        two_jump_pre = []\n",
    "        two_jump_f1 = 0\n",
    "        two_jump_vec = np.zeros(7)\n",
    "        two_jump_score = 0\n",
    "    \n",
    "    return two_jump_pre,two_jump_raw,two_jump_f1,two_jump_vec,two_jump_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构造数量和相似度特征"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构造特征用函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"scaler_07_18_18_30.bin\",\"rb\") as f:\n",
    "    scaler = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_to_feature(seq_to_feature_ss,seq_to_feature_ans):\n",
    "\n",
    "    #pattern = \"(\" + \"|\".join(stop_words)+\")\"\n",
    "    #seq = re.sub(pattern,\"\",seq_to_feature_ss)\n",
    "    #print(seq_to_feature_ss)\n",
    "    \n",
    "    seq = seq_to_feature_ss\n",
    "    \n",
    "    for key in SYNONYM_MAP:\n",
    "        if key in seq_to_feature_ss:\n",
    "            seq = seq.replace(key,SYNONYM_MAP[key])\n",
    "    \n",
    "                   \n",
    "    ans = seq_to_feature_ans\n",
    "\n",
    "    final_feature = []\n",
    "    final_feature.append(q_index)\n",
    "    final_feature.append(one_jump_feature(ans,seq,[]))\n",
    "    final_feature.append(two_jump_feature(ans,seq,[]))\n",
    "    \n",
    "    return final_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_for_cnn(final_feature,final_feature_scaler = scaler):\n",
    "    index,one,two = final_feature\n",
    "    #ss = df[\"question\"][index]\n",
    "    this_feature = []\n",
    "    pattern = re.compile(\"[\\\"“”‘’''\\<\\>]\")\n",
    "    \n",
    "    pre,path,F1,feature,score = two\n",
    "    for key in two[1]:\n",
    "        char = \"\"\n",
    "        line = two[1][key]\n",
    "        prop = line[1] + line[3]\n",
    "        if len(line) > 5:\n",
    "            roots = (line[0][0],line[5])\n",
    "        else:\n",
    "            roots = (line[0][0])\n",
    "        char = \"\".join(roots) + line[1] + line[3]        \n",
    "        this_feature.append((pattern.sub(\"\",char),pattern.sub(\"\",prop),ss,F1))\n",
    "\n",
    "    pre,path,F1,feature,score = one\n",
    "    char = \"\"\n",
    "    prop = \"\"\n",
    "    for key in one[1]:\n",
    "        path = one[1][key][\"path\"]\n",
    "        for line in path:\n",
    "            tmp = line[0] + line[2]\n",
    "        if tmp not in char:\n",
    "            char += tmp \n",
    "            prop += line[2] \n",
    "            this_feature.append((pattern.sub(\"\",char),pattern.sub(\"\",prop),ss,F1))\n",
    "    \n",
    "    test_pre = []\n",
    "    test_que = []\n",
    "    test_ans = []\n",
    "    for row in this_feature:\n",
    "        pre,prop,que,key = row\n",
    "\n",
    "        tmp_pre = np.array(seq_to_vec(pre,SAMPLE_LENGTH))\n",
    "        tmp_que = np.array(seq_to_vec(que,SAMPLE_LENGTH))\n",
    "        test_pre.append(tmp_pre)\n",
    "        test_que.append(tmp_que)\n",
    "        test_ans.append(key)\n",
    "    test_pre = np.array(test_pre)\n",
    "    test_que = np.array(test_que)\n",
    "    try:\n",
    "        t_test_pre = final_feature_scaler.transform(test_pre.reshape(-1,64)).reshape(-1,SAMPLE_LENGTH,64)\n",
    "        t_test_que = final_feature_scaler.transform(test_que.reshape(-1,64)).reshape(-1,SAMPLE_LENGTH,64)\n",
    "    \n",
    "        test_x = [t_test_pre,t_test_que] * 5\n",
    "    except ValueError:\n",
    "        return [],[]\n",
    "    return test_x,test_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构造特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(\"file.txt\", binary=False,encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "0 ﻿德国有哪些著名的汽车品牌\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "1 微软公司有什么软件产品\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "2 美国总统奥巴马出生在什么地方\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "3 麻省理工学院的创建者是\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "4 舒伯特是哪国人\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "5 \"商鞅变法\"发生于哪个时代\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "6 第一部《异形》的导演是谁\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "7 曲毛楼梯草的主要分布在哪\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "8 汤显祖是哪个朝代的人\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "9 暗夜女神勒托出自哪个神话体系\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "10 魅族CEO是谁\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "11 柳明珠的主要成就是什么\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-a042b49cd174>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#ans = get_ans(ss,10)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_test_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mbrige\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseq_to_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mtotal_test_feature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbrige\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-4263aa6b590c>\u001b[0m in \u001b[0;36mseq_to_feature\u001b[0;34m(seq_to_feature_ss, seq_to_feature_ans)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mfinal_feature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mfinal_feature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone_jump_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mfinal_feature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtwo_jump_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfinal_feature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-dc1c6915225b>\u001b[0m in \u001b[0;36mtwo_jump_feature\u001b[0;34m(two_jump_feature_ans, two_jump_feature_ss, two_jump_feature_label)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtwo_jump_raw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mfff\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mraw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtwo_jump_solver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtwo_jump_feature_ans\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtwo_jump_feature_ss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0maaa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdown_to_low\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maaa\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/songlei1994/ccks/data/two_jump.py\u001b[0m in \u001b[0;36mtwo_jump_solver\u001b[0;34m(two_jump_solver_ans, two_jump_solver_ss)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m  \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mans_for_select\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                         \u001b[0mans_for_select\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjump_hint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0medge\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprop_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minfor_1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minfor_2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minfor_3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjump_hint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0medge\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m                         \u001b[0mans_raw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mroots\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtmp_first_edge\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0medge\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "question = open(\"task4coqa_test.questions\",\"rb\").read().decode(\"utf8\").split(\"\\r\\n\")\n",
    "total_test_feature = [] \n",
    "for num,ss in enumerate(question,0):\n",
    "    ss = re.sub(\"(q\\d{1,4}:|？)\",\"\",ss)\n",
    "    print(\"-\"*130)\n",
    "    print(num,ss)\n",
    "    q_index = num\n",
    "    #ans = get_ans(ss,10)\n",
    "    ans = final_test_cache[num][1]\n",
    "    brige = seq_to_feature(ss,ans)\n",
    "    total_test_feature.append((num,brige))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 或者读取total_test_feature缓存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"total_test_feature_07_20_13_11.bin\",\"rb\") as f:\n",
    "    total_test_feature = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_to_vec(seq_to_vec_seq,length = SAMPLE_LENGTH):\n",
    "    x = []\n",
    "    for row in seq_to_vec_seq[:length]:\n",
    "        #print(row)\n",
    "        if row in model:\n",
    "            x.append(model[row.upper()])\n",
    "\n",
    "    for i in range(length - len(x)):\n",
    "        x.append(model[\"<PAD>\"])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取CNN模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = load_model(\"final_cnn.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取字向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fff_feature = []\n",
    "for num,brige in total_test_feature:\n",
    "    \n",
    "    tmp_feature = []\n",
    "    #brige = (num,one,two,mul)\n",
    "    num,one,two = brige\n",
    "    \n",
    "    test_x,test_ans = feature_for_cnn(brige)\n",
    "    if not test_x:\n",
    "        test_fff_feature.append(np.zeros(16))\n",
    "        continue\n",
    "    else:\n",
    "        #submit.append(())\n",
    "        pass\n",
    "    test_y = sim.predict(test_x)[:,0]\n",
    "    \n",
    "    try:\n",
    "        one_pre_score = test_y[[x in one[0] for x in test_ans]].max()\n",
    "    except ValueError :\n",
    "        one_pre_score = 0\n",
    "    try:\n",
    "        two_pre_score = test_y[[x in two[0] for x in test_ans]].max()\n",
    "    except ValueError:\n",
    "        two_pre_score = 0\n",
    "    tmp_feature.extend((one_pre_score,two_pre_score))\n",
    "    #这里一定要回到分类器，不然会丢失很多东西\n",
    "    # 但也有可能有好处\n",
    "   \n",
    "    tmp_feature.extend(one[3])\n",
    "    tmp_feature.extend(two[3])\n",
    "    \n",
    "    tmp_feature.extend((two[4],one[4]))\n",
    "    \n",
    "    test_fff_feature.append(tmp_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  感知机分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"scaler_2_07_20_12_56.bin\",\"rb\") as f:\n",
    "    scaler_2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_y = scaler_2.transform(np.array(test_fff_feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = load_model(\"final_model_07_18.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnn = final_model.predict(np.array(submit_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nnn_07_20_17_18.bin\n"
     ]
    }
   ],
   "source": [
    "save_to_disk(nnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 生成感知机答案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = []\n",
    "for num,brige in total_test_feature:\n",
    "    index,one,two = brige\n",
    "    ans_list = [one,two]\n",
    "    aaa = nnn.argmax(axis = 1)[num]\n",
    "    #print(aaa)\n",
    "    try:\n",
    "        submit.append(ans_list[int(aaa)][0])\n",
    "    except TypeError:\n",
    "        submit.append([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"result_ss_new.txt\",\"wb\") as f:\n",
    "    for line in submit[:-1]:\n",
    "        line = \"\\t\".join(line) + \"\\r\\n\"\n",
    "        f.write(line.encode(\"utf8\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "339px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
